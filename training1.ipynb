{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asmahassouna/rep1/blob/main/training1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "veXDpQ9M6l0i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a88cdcc6-d188-476e-9c25-b5d36b1a4cd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-3.1416, -3.1384, -3.1353,  ...,  3.1353,  3.1384,  3.1416])\n",
            "tensor([ 8.7423e-08, -3.1430e-03, -6.2863e-03,  ...,  6.2863e-03,\n",
            "         3.1430e-03, -8.7423e-08])\n",
            "99 4240.34814453125\n",
            "199 3001.4228515625\n",
            "299 2125.319091796875\n",
            "399 1505.75732421875\n",
            "499 1067.5972900390625\n",
            "599 757.71337890625\n",
            "699 538.542724609375\n",
            "799 383.5251159667969\n",
            "899 273.8785705566406\n",
            "999 196.32138061523438\n",
            "1099 141.46060180664062\n",
            "1199 102.65320587158203\n",
            "1299 75.20109558105469\n",
            "1399 55.78110885620117\n",
            "1499 42.04282760620117\n",
            "1599 32.32381057739258\n",
            "1699 25.447996139526367\n",
            "1799 20.583580017089844\n",
            "1899 17.142086029052734\n",
            "1999 14.707247734069824\n",
            "2099 12.984589576721191\n",
            "2199 11.765787124633789\n",
            "2299 10.903457641601562\n",
            "2399 10.293336868286133\n",
            "2499 9.861647605895996\n",
            "2599 9.556207656860352\n",
            "2699 9.340093612670898\n",
            "2799 9.187176704406738\n",
            "2899 9.078981399536133\n",
            "2999 9.002423286437988\n",
            "Result: y = -0.014397397637367249 + 0.8572241067886353 x + 0.0024837900418788195 x^2 + -0.09339912980794907 x^3\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import math\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "dtype = torch.float\n",
        "device = torch.device(\"cpu\")\n",
        "# device = torch.device(\"cuda:0\") # Uncomment this to run on GPU\n",
        "\n",
        "# Create random input and output data\n",
        "x = torch.linspace(-math.pi, math.pi, 2000, device=device, dtype=dtype)\n",
        "y = torch.sin(x)\n",
        "print(x)\n",
        "print(y)\n",
        "\n",
        "# Randomly initialize weights\n",
        "a = torch.randn((), device=device, dtype=dtype)\n",
        "b = torch.randn((), device=device, dtype=dtype)\n",
        "c = torch.randn((), device=device, dtype=dtype)\n",
        "d = torch.randn((), device=device, dtype=dtype)\n",
        "\n",
        "learning_rate = 1e-6\n",
        "for t in range(3000):\n",
        "    # Forward pass: compute predicted y\n",
        "    y_pred = a + b * x + c * x ** 2 + d * x ** 3\n",
        "\n",
        "    # Compute and print loss\n",
        "    loss = (y_pred - y).pow(2).sum().item()\n",
        "    if t % 100 == 99:\n",
        "        print(t, loss)\n",
        "\n",
        "    # Backprop to compute gradients of a, b, c, d with respect to loss\n",
        "    grad_y_pred = 2.0 * (y_pred - y)\n",
        "    grad_a = grad_y_pred.sum()\n",
        "    grad_b = (grad_y_pred * x).sum()\n",
        "    grad_c = (grad_y_pred * x ** 2).sum()\n",
        "    grad_d = (grad_y_pred * x ** 3).sum()\n",
        "\n",
        "    # Update weights using gradient descent\n",
        "    a -= learning_rate * grad_a\n",
        "    b -= learning_rate * grad_b\n",
        "    c -= learning_rate * grad_c\n",
        "    d -= learning_rate * grad_d\n",
        "\n",
        "\n",
        "print(f'Result: y = {a.item()} + {b.item()} x + {c.item()} x^2 + {d.item()} x^3')"
      ]
    }
  ]
}