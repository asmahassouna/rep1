{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMDiHYvvdOqCdWy3GRodA6b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asmahassouna/rep1/blob/main/training1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "veXDpQ9M6l0i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "917fe491-f0dc-4f7a-e419-59fceb6b8290"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99 612.9024047851562\n",
            "199 427.5925598144531\n",
            "299 299.4073791503906\n",
            "399 210.64695739746094\n",
            "499 149.12496948242188\n",
            "599 106.44174194335938\n",
            "699 76.80072021484375\n",
            "799 56.19810485839844\n",
            "899 41.865089416503906\n",
            "999 31.88534164428711\n",
            "1099 24.931011199951172\n",
            "1199 20.081018447875977\n",
            "1299 16.69603729248047\n",
            "1399 14.331817626953125\n",
            "1499 12.679399490356445\n",
            "1599 11.523681640625\n",
            "1699 10.714845657348633\n",
            "1799 10.148441314697266\n",
            "1899 9.751556396484375\n",
            "1999 9.473304748535156\n",
            "2099 9.278120040893555\n",
            "2199 9.14113998413086\n",
            "2299 9.044957160949707\n",
            "2399 8.97739028930664\n",
            "2499 8.929906845092773\n",
            "2599 8.896523475646973\n",
            "2699 8.873043060302734\n",
            "2799 8.856522560119629\n",
            "2899 8.844894409179688\n",
            "2999 8.836708068847656\n",
            "Result: y = -0.004537998232990503 + 0.8556941151618958 x + 0.0007828816305845976 x^2 + -0.09318150579929352 x^3\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import math\n",
        "\n",
        "\n",
        "dtype = torch.float\n",
        "device = torch.device(\"cpu\")\n",
        "# device = torch.device(\"cuda:0\") # Uncomment this to run on GPU\n",
        "\n",
        "# Create random input and output data\n",
        "x = torch.linspace(-math.pi, math.pi, 2000, device=device, dtype=dtype)\n",
        "y = torch.sin(x)\n",
        "\n",
        "# Randomly initialize weights\n",
        "a = torch.randn((), device=device, dtype=dtype)\n",
        "b = torch.randn((), device=device, dtype=dtype)\n",
        "c = torch.randn((), device=device, dtype=dtype)\n",
        "d = torch.randn((), device=device, dtype=dtype)\n",
        "\n",
        "learning_rate = 1e-6\n",
        "for t in range(3000):\n",
        "    # Forward pass: compute predicted y\n",
        "    y_pred = a + b * x + c * x ** 2 + d * x ** 3\n",
        "\n",
        "    # Compute and print loss\n",
        "    loss = (y_pred - y).pow(2).sum().item()\n",
        "    if t % 100 == 99:\n",
        "        print(t, loss)\n",
        "\n",
        "    # Backprop to compute gradients of a, b, c, d with respect to loss\n",
        "    grad_y_pred = 2.0 * (y_pred - y)\n",
        "    grad_a = grad_y_pred.sum()\n",
        "    grad_b = (grad_y_pred * x).sum()\n",
        "    grad_c = (grad_y_pred * x ** 2).sum()\n",
        "    grad_d = (grad_y_pred * x ** 3).sum()\n",
        "\n",
        "    # Update weights using gradient descent\n",
        "    a -= learning_rate * grad_a\n",
        "    b -= learning_rate * grad_b\n",
        "    c -= learning_rate * grad_c\n",
        "    d -= learning_rate * grad_d\n",
        "\n",
        "\n",
        "print(f'Result: y = {a.item()} + {b.item()} x + {c.item()} x^2 + {d.item()} x^3')"
      ]
    }
  ]
}